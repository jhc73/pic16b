{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, numpy as np, pandas as pd, tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Read & prepare data\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "df[\"is_viral\"] = ((df[\"views\"] > 100_000) & (df[\"likes\"] > 10_000)).astype(int)\n",
    "\n",
    "os.makedirs(\"thumbnails\", exist_ok=True)\n",
    "def download_thumb(video_id, url):\n",
    "    path = f\"thumbnails/{video_id}.jpg\"\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=5); r.raise_for_status()\n",
    "            with open(path, \"wb\") as f:  f.write(r.content)\n",
    "        except Exception:  return None\n",
    "    return path\n",
    "\n",
    "df[\"thumbnail_path\"] = df.apply(\n",
    "    lambda r: download_thumb(r[\"video_id\"], r[\"thumbnail_link\"]), axis=1)\n",
    "df = df[df[\"thumbnail_path\"].notna()].reset_index(drop=True)\n",
    "\n",
    "# tf.data pipeline\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "def load_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = preprocess_input(img)          # ResNet pre processing\n",
    "    return img\n",
    "\n",
    "# TextVectorization -> TF-IDF\n",
    "VOCAB = 2000\n",
    "vectorize = layers.TextVectorization(\n",
    "    max_tokens=VOCAB,\n",
    "    output_mode=\"tf_idf\"     # direct output TF-IDF\n",
    ")\n",
    "vectorize.adapt(df[\"title\"])\n",
    "\n",
    "def make_example(title, path, label):\n",
    "    return {\"title\": title, \"thumbnail\": path}, label\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x[\"title\"] = vectorize(x[\"title\"])          # [batch, VOCAB] float\n",
    "    x[\"thumbnail\"] = load_image(x[\"thumbnail\"]) # [batch,224,224,3]\n",
    "    return x, tf.expand_dims(tf.cast(y, tf.float32), -1)\n",
    "\n",
    "ds = (tf.data.Dataset.from_tensor_slices(\n",
    "        (df[\"title\"], df[\"thumbnail_path\"], df[\"is_viral\"]))\n",
    "      .map(make_example, num_parallel_calls=AUTOTUNE)\n",
    "      .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "      .shuffle(1024).batch(32).prefetch(AUTOTUNE))\n",
    "\n",
    "# Model create\n",
    "# Text branch\n",
    "text_in   = tf.keras.Input(shape=(VOCAB,), dtype=\"float32\", name=\"title\")\n",
    "x_text    = layers.Dense(256, activation=\"relu\")(text_in)   # Dimensionality reduction\n",
    "x_text    = layers.Dropout(0.3)(x_text)\n",
    "\n",
    "# Image branch (pretrained ResNet)\n",
    "img_in    = tf.keras.Input(shape=(*IMG_SIZE, 3), name=\"thumbnail\")\n",
    "base_cnn  = ResNet50(include_top=False, weights=\"imagenet\", pooling=\"avg\")\n",
    "base_cnn.trainable = False                    # Phase 1 freeze first\n",
    "x_img     = base_cnn(img_in, training=False)  # [batch, 2048]\n",
    "\n",
    "# Merge & output\n",
    "x = layers.concatenate([x_text, x_img])\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs={\"title\": text_in, \"thumbnail\": img_in}, outputs=out)\n",
    "\n",
    "# Training \n",
    "labels = df[\"is_viral\"].values\n",
    "cw = class_weight.compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = {i: w for i, w in enumerate(cw)}\n",
    "\n",
    "# Phase 1: Train only top layers\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_phase1 = model.fit(ds, epochs=3, class_weight=class_weights)\n",
    "\n",
    "# Phase 2: Unfreeze last 10 layers for fine-tuning\n",
    "for layer in base_cnn.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),   # Small learning rate\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history_phase2 = model.fit(ds, epochs=5, class_weight=class_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
