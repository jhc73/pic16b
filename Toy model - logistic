# =============================
# Just Kaggle small dataset 
# =============================
import pandas as pd

df = pd.read_csv('USvideos.csv', encoding='latin1')
df = df[['video_id', 'title', 'tags', 'views', 'likes', 'comment_count', 'thumbnail_link']]
df.dropna(inplace=True)

# def of（viral） 
df['is_viral'] = (df['likes'] > 10000) & (df['views'] > 1_000_000)

# =============================
# the tumbnail column in csv(pic)
# =============================
import os
import requests

os.makedirs('thumbnails', exist_ok=True)

def download_thumbnail(row):
    video_id = row['video_id']
    url = row['thumbnail_link']
    path = f'thumbnails/{video_id}.jpg'
    if not os.path.exists(path):
        try:
            r = requests.get(url, timeout=10)
            with open(path, 'wb') as f:
                f.write(r.content)
            print(f'Downloaded: {video_id}')
        except Exception as e:
            print(f'Failed: {video_id} - {e}')

df.head(100).apply(download_thumbnail, axis=1)  # 

# =============================
# get vec
# =============================
import torch
from torchvision import models, transforms
from PIL import Image
import numpy as np
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet = models.resnet18(pretrained=True)
resnet.fc = torch.nn.Identity()  # remove
resnet = resnet.to(device)
resnet.eval()

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

def extract_image_feature(image_path):
    try:
        img = Image.open(image_path).convert('RGB')
        img_tensor = transform(img).unsqueeze(0).to(device)
        with torch.no_grad():
            features = resnet(img_tensor)
        return features.squeeze().cpu().numpy()
    except:
        return None

features = []
for vid in tqdm(df['video_id'].head(100)):
    path = f'thumbnails/{vid}.jpg'
    if os.path.exists(path):
        vec = extract_image_feature(path)
    else:
        vec = None
    features.append(vec)

df = df.head(100).copy()
df['image_feature'] = features
df = df[df['image_feature'].notnull()]  # del null

# =============================
# stand
# =============================
from sklearn.preprocessing import StandardScaler

X_num = df[['views', 'likes', 'comment_count']]
scaler = StandardScaler()
X_num_scaled = scaler.fit_transform(X_num)

X_img = np.vstack(df['image_feature'].values)
X = np.hstack([X_img, X_num_scaled])
y = df['is_viral'].astype(int).values

# =============================
# log reg
# =============================
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))
